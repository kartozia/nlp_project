## Text segmentation in OpenCorpora project
Под сегментацией текста в данной статье подразумевается деление текста на слова и предложения. В рамках OpenCorpora была проведена работа по сегментации текстов общим объёмом более 600 тыс. словоупотреблений. На основе полученных данных была обучена математическая модель сегментации текста. Модель представляет собой вероятностный бинарный классификатор.

### **Проблема с текстами**
Все тексты, входящие в корпус, опубликованы на условиях, совместимых с лицензией СС-BY-SA. Это позволяет сделать корпус целиком доступным, но сужает круг материалов.

### **Входные данные**
При проектировании модуля сегментации важно понимать, что никакая лингвистическая информация по умолчанию не предполагается доступной во время сегментации.  На вход модуль сегментации получает последовательность знаков (буквы кириллицы и других алфавитов, знаков пунктуации, цифр, пробельных символов и других знаков, предусмотренных кодировкой знаков Unicode).

### **Единицы сегментации и классификация токенов**
**Важно!** *Вопросы сегментации текста решаются **только** в модуле сегментации.*
Единицами сегментации являются токены, предложения и абзацы. Абзацы состоят из предложения, а предложения, в свою очередь, — из токенов. 
Токены, являющиеся словами, на последующих этапах обработки текста получат морфологическую интерпретацию. Токенам другого типа будет присвоен соответствующий класс сущностей: знаки препинания, числа, цифробуквенные комплексы, интернет-адреса. Предложения станут объектами синтаксического анализа и получат синтаксические разборы.
Таким образом, при делении последовательности знаков на токены решается вопрос станет ли данная цепочка объектом морфологического анализа, а после лексико-семантического или синтаксического анализа.

### **Токеном считаются:**
1. Пробелы всегда разделяют токены. Все цепочки, включающие пробел, но обозначающие одну сущность (напр. Старая Басманная), будут объединены на последующих этапах анализа.
1. Знаки препинания, состоящие из одного и более знаков (точка в конце предложения и после сокращенного слова, запятая, вопросительный и восклицательные знаки, многоточия, несколько идущих подряд одинаковых знаков препинания.
1. Числа, включающие точку или запятую в качестве разделителя целой и дробной частей , обыкновенные дроби, числа со степень, интернет адреса и химические формулы. С точки зрения лингвистического анализа текста, здесь значение имеет только класс выделенной цепочки.
1. Имена собственные, содержащие внутри знаки препинания (“Яндекс.Деньги”, “Санкт-Петербург”, “О.С.П.-студия”). Подобные имена могут быть написаны самыми разными способами и могут включать не только точки и дефисы, но и другие знаки (@, #, $ и пр.)
1. Обозначение единиц измерения (“км”, “$”, “%” и пр.), а также “+” и “-“ перед числами отделяются от числа и становятся отдельными токенами, даже если между ними и числом нет пробелов
1. Частицы, написанные через дефис с другими словами (“они-то”, “подойди-ка”, “он-таки”, “точно-с”, “он-де” и пр.). Получается, что “они-то” это три разных токена: “они”, “-”, “то”.
1. Повторяющиеся слова, написанные через дефис (“ха-ха-ха”, “много-много”, “красный-красный”)
1. Существительные, написанные через дефис и не подпадающие под предыдущие случаи, разделяются, если словарной статьи с таким заголовком нет ни в толковом, ни в орфографическом словаре (проверка выполняется по коллекции Яндекс.Словарей)

### **Предложением считаются:**
1. Множество токеном между знаком конца предыдущего предложения/абзаца + заглавной буквы и знаком конца текущего предложения/абзаца.
1. Проблемы возникают с прямой речью и цитированием:
1. Прямая речь отделяется от слов автора, даже когда слова автора не начинаются с заглавной буквы, а в конце прямой речи нет знака препинания, обозначающего конец предложения
1. При цитировании, оформленном при помощи кавычек, границы предложений расставляются по основному правилу, т.е. по знаку препинания, обозначающему конец предложения и началу следующего с заглавной буквы.
1. Если цитируется название художественного произведения, включающее в себя несколько предложений, то границы внутри названия не ставятся.
1. Плюсом такого деления, является то, что сохраняется синтаксическая целостность предложения.

### **Золотой стандарт и автоматическая сегментация**
В качестве обучающего множества используются все токенизированные вручную предложения корпуса. Каждое предложение представлено в виде пары (*s*,*T*), где *s* — исходная, нетокенизрованная запись предложения (=строка), а *T* — упорядоченное множество токенов, на которые оно разбито. Склеив по порядку все элементы *T*, всегда можно получить *s*.
Применение модели для токенизации текста выглядит так: в каждой позиции текста по тем же правилам, что и при обучении, вычислить вектор двоичных признаков, найти в таблице соответствующую вероятность и решить, достаточно ли эта вероятность высока для постановки границ в данной позиции. Для сегментации на предложения используется схожая модель, но использующая деревья решений.
В модуле сегментации используются также контекстные функции, которые работают с левым или правом контекстом:
* “является ли символ слева буквой кириллицы”
* “является ли символ справа дефисом”
* “является ли символ справа закрывающей скобкой любого вида” и т.п.
Некоторые контекстные функции требуют внешних источников информации (напр., список всех словарных слов с дефисом или список исключений)

### **Порог отсечения и оценка качества**
Порог отсечение — значение вероятности, начиная с которого следует считать границу “достаточно” вероятно. Если по каким-то причинам важнее, допустим, максимизировать полноту за счёт точности, то порог имеет смысл снизить примерно до **0,01**.
Точность в данном случае оценивается путем подсчёта количества ошибок, которая модель допускает при классификации объектов из корпуса. Ошибки бывают **двух** видов: ложное срабатывание (неверно поставленная границы) и пропуск события (пропуск правильной границы). При оценке также использовалась техника кросс-валидации. Случаи расставления  границ до и после пробелов не учитывались, так как, по правилам, пробел — всегда разделитель токенов.

### **Преимущества и недостатки метода**
**Плюсы:**
* менять поведение токенизатора на некотором классе случаев проще при использовании статистических методов
* удобно использовать, когда детали стандарта токенизации не очень важны

**Минусы:**
* невысокая скорость работы при обучении и классификации
* зависимость от качества обучающих примеров
* необходимость существования размеченного множества примеров для первичного обучения
